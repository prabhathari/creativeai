# Gemini LLM Simple Call Example

This project demonstrates how to send a prompt to the Gemini LLM model and print the response using Python.

## Requirements
- Python 3.8+
- `requests` library

## Setup
1. Install dependencies:
   ```sh
   pip install requests
   ```
2. Set your Gemini API key as an environment variable:
   ```sh
   $env:GEMINI_API_KEY = "your_api_key_here"
   ```
   Replace `your_api_key_here` with your actual Gemini API key.

## Usage
Run the script and enter your prompt when asked:
```sh
python gemini_llm_call.py
```
